{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1842941f-de6b-4c88-a3e3-ae15db1851c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD  TAX  PTRATIO  \\\n",
      "0  0.00632  18.0   2.31     0  0.538  6.575  65.2  4.0900    1  296     15.3   \n",
      "1  0.02731   0.0   7.07     0  0.469  6.421  78.9  4.9671    2  242     17.8   \n",
      "2  0.02729   0.0   7.07     0  0.469  7.185  61.1  4.9671    2  242     17.8   \n",
      "3  0.03237   0.0   2.18     0  0.458  6.998  45.8  6.0622    3  222     18.7   \n",
      "4  0.06905   0.0   2.18     0  0.458  7.147  54.2  6.0622    3  222     18.7   \n",
      "\n",
      "   LSTAT  MEDV  CAT. MEDV  TargetClass  \n",
      "0   4.98  24.0          0            1  \n",
      "1   9.14  21.6          0            1  \n",
      "2   4.03  34.7          1            1  \n",
      "3   2.94  33.4          1            1  \n",
      "4   5.33  36.2          1            1  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv(r\"C:\\Users\\atand\\Downloads\\BostonHousing.csv\")\n",
    "\n",
    "# Create a target class: High-value (1) if MEDV > median, else Low-value (0)\n",
    "median_medv = df['MEDV'].median()  # Use uppercase 'MEDV'\n",
    "df['TargetClass'] = (df['MEDV'] > median_medv).astype(int)  # Use uppercase 'MEDV'\n",
    "\n",
    "# Display the first few rows to verify the new column\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "83463e08-abf9-4e12-8b1e-fccf16b6637d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target Class Distribution:\n",
      "TargetClass\n",
      "0    256\n",
      "1    250\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv(r\"C:\\Users\\atand\\Downloads\\BostonHousing.csv\")\n",
    "\n",
    "# Create a target class: High-value (1) if MEDV > median, else Low-value (0)\n",
    "median_medv = df['MEDV'].median()\n",
    "df['TargetClass'] = (df['MEDV'] > median_medv).astype(int)\n",
    "\n",
    "# Check the target class\n",
    "print(\"Target Class Distribution:\")\n",
    "print(df['TargetClass'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "684baa92-5b2d-4674-a20e-fc2a32051a31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class distribution:\n",
      "TargetClass\n",
      "0    256\n",
      "1    250\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check balance of classes\n",
    "print(\"Class distribution:\")\n",
    "print(df['TargetClass'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f23142be-348d-413d-b781-631766d5a8ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5afd158d-22c9-4e75-9ada-697311dd4594",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define features and target class\n",
    "X = df.drop(['MEDV', 'TargetClass'], axis=1)  # Features\n",
    "y = df['TargetClass']                          # Target class\n",
    "\n",
    "# Apply SMOTE for oversampling\n",
    "smote = SMOTE(random_state=42)\n",
    "X_resampled, y_resampled = smote.fit_resample(X, y)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f6615f62-9f03-48ed-be36-404201f45d11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kNN Results:\n",
      "Accuracy: 0.8252\n",
      "Precision: 0.7812\n",
      "Recall: 0.9259\n",
      "F1 Score: 0.8475\n",
      "ROC AUC: 0.8607\n"
     ]
    }
   ],
   "source": [
    "# kNN Classifier\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "knn.fit(X_train, y_train)\n",
    "y_pred_knn = knn.predict(X_test)\n",
    "\n",
    "# Evaluate kNN\n",
    "accuracy_knn = accuracy_score(y_test, y_pred_knn)\n",
    "precision_knn = precision_score(y_test, y_pred_knn)\n",
    "recall_knn = recall_score(y_test, y_pred_knn)\n",
    "f1_knn = f1_score(y_test, y_pred_knn)\n",
    "roc_auc_knn = roc_auc_score(y_test, knn.predict_proba(X_test)[:, 1])\n",
    "\n",
    "print(\"kNN Results:\")\n",
    "print(f\"Accuracy: {accuracy_knn:.4f}\")\n",
    "print(f\"Precision: {precision_knn:.4f}\")\n",
    "print(f\"Recall: {recall_knn:.4f}\")\n",
    "print(f\"F1 Score: {f1_knn:.4f}\")\n",
    "print(f\"ROC AUC: {roc_auc_knn:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3a983d87-32d0-4a0d-85bc-e423473286f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Results:\n",
      "Accuracy: 0.7961\n",
      "Precision: 0.7797\n",
      "Recall: 0.8519\n",
      "F1 Score: 0.8142\n",
      "ROC AUC: 0.7933\n"
     ]
    }
   ],
   "source": [
    "# Decision Tree Classifier\n",
    "dt = DecisionTreeClassifier(random_state=42)\n",
    "dt.fit(X_train, y_train)\n",
    "y_pred_dt = dt.predict(X_test)\n",
    "\n",
    "# Evaluate Decision Tree\n",
    "accuracy_dt = accuracy_score(y_test, y_pred_dt)\n",
    "precision_dt = precision_score(y_test, y_pred_dt)\n",
    "recall_dt = recall_score(y_test, y_pred_dt)\n",
    "f1_dt = f1_score(y_test, y_pred_dt)\n",
    "roc_auc_dt = roc_auc_score(y_test, dt.predict_proba(X_test)[:, 1])\n",
    "\n",
    "print(\"Decision Tree Results:\")\n",
    "print(f\"Accuracy: {accuracy_dt:.4f}\")\n",
    "print(f\"Precision: {precision_dt:.4f}\")\n",
    "print(f\"Recall: {recall_dt:.4f}\")\n",
    "print(f\"F1 Score: {f1_dt:.4f}\")\n",
    "print(f\"ROC AUC: {roc_auc_dt:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47be9149-7d80-4ff9-ac6d-ef0617653ca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Объяснение результатов\n",
    "Точность:\n",
    "\n",
    "Точность kNN выше (0,8252) по сравнению с деревом решений (0,7961). Это указывает на то, что kNN правильно классифицирует большую долю экземпляров в тестовом наборе.\n",
    "Точность:\n",
    "\n",
    "Оба классификатора имеют схожие показатели точности: kNN - 0,7812, а Decision Tree - 0,7797. Точность измеряет долю истинно положительных предсказаний среди всех положительных предсказаний. Это говорит о том, что обе модели достаточно хорошо справляются с минимизацией ложных срабатываний.\n",
    "Recall:\n",
    "\n",
    "kNN имеет значительно более высокий показатель recall (0,9259) по сравнению с деревом решений (0,8519). Recall измеряет долю истинно положительных предсказаний среди всех реально положительных случаев. Это указывает на то, что kNN лучше выявляет положительные случаи (дома с высокой стоимостью), чем дерево решений, которое может пропустить больше положительных случаев.\n",
    "F1 Score:\n",
    "\n",
    "Показатель F1 для kNN (0,8475) выше, чем у Дерева решений (0,8142). Показатель F1 - это среднее гармоническое значение точности и запоминания, обеспечивающее баланс между двумя метриками. Это говорит о том, что kNN достигает лучшего баланса между точностью и отзывом по сравнению с Деревом решений.\n",
    "ROC AUC:\n",
    "\n",
    "kNN также превосходит Дерево решений по показателю ROC AUC (0,8607 против 0,7933). Показатель ROC AUC указывает на способность модели различать положительные и отрицательные классы. Более высокое значение ROC AUC для kNN говорит о том, что она лучше ранжирует положительные экземпляры, чем отрицательные.\n",
    "Краткие выводы\n",
    "Общая производительность: kNN превосходит дерево решений по всем метрикам, что указывает на то, что он является более эффективным классификатором для данного набора данных.\n",
    "Сильные стороны kNN: Высокие показатели recall и F1 свидетельствуют о том, что kNN особенно эффективно определяет дома с высокой стоимостью, что очень важно для приложений, в которых пропуск положительного экземпляра (ложноотрицательный) обходится дороже, чем неправильная классификация отрицательного экземпляра (ложноположительный).\n",
    "Ограничения дерева решений: Несмотря на то, что дерево решений показывает достаточно хорошие результаты, его более низкие показатели recall и ROC AUC указывают на то, что оно может быть не столь эффективным в определении домов с высокой стоимостью по сравнению с kNN.\n",
    "Заключение\n",
    "В заключение следует отметить, что классификатор kNN является лучшим выбором для данной задачи классификации, исходя из оценочных показателей. Однако при выборе модели важно учитывать контекст задачи и последствия ложноположительных и ложноотрицательных результатов. Дальнейшая настройка гиперпараметров и изучение других алгоритмов классификации также могут привести к улучшению результатов.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SCILEARN-KERNEL",
   "language": "python",
   "name": "scilearn-kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
